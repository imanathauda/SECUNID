{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"H954WUqsvWba"},"outputs":[{"name":"stdout","output_type":"stream","text":["device:  cpu\n","Using downloaded and verified file: ./data/cifar-10-python.tar.gz\n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n","hostile_nodes: ['y_train25', 'y_train85', 'y_train96', 'y_train89', 'y_train65', 'y_train94', 'y_train5', 'y_train35', 'y_train36', 'y_train92', 'y_train71', 'y_train52', 'y_train24', 'y_train16', 'y_train60', 'y_train87', 'y_train53', 'y_train98', 'y_train47', 'y_train49']\n","Iteration 1 : main_model accuracy on all test data:  0.1012\n","Iteration 2 : main_model accuracy on all test data:  0.1299\n","Iteration 3 : main_model accuracy on all test data:  0.1492\n","Iteration 4 : main_model accuracy on all test data:  0.1613\n"]},{"data":{"text/plain":["\u003cmodule 'matplotlib.pyplot' from '/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py'\u003e"]},"execution_count":2,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 1000x600 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","import numpy as np\n","from torch.optim import lr_scheduler\n","import matplotlib.pyplot as plt  # Added for plotting\n","import pandas as pd  # Added for CSV file handling\n","\n","# Contents of construct_models.py\n","\n","import torch.nn.functional as F\n","\n","def weights_init(model, torch_manual_seed=2304):\n","    torch.manual_seed(torch_manual_seed)\n","    torch.cuda.manual_seed_all(torch_manual_seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    for m in model.modules():\n","        if isinstance(m, nn.Conv2d):\n","            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","        elif isinstance(m, nn.Linear):\n","            nn.init.xavier_normal_(m.weight)\n","            nn.init.constant_(m.bias, 0)\n","        elif isinstance(m, nn.BatchNorm2d):\n","            nn.init.constant_(m.weight, 1)\n","            nn.init.constant_(m.bias, 0)\n","\n","def learning_rate_decay(optimizer_dict, decay_rate):\n","    for i in range(len(optimizer_dict)):\n","        optimizer_name = \"optimizer\" + str(i)\n","        old_lr = optimizer_dict[optimizer_name].param_groups[0][\"lr\"]\n","        optimizer_dict[optimizer_name].param_groups[0][\"lr\"] = old_lr * decay_rate\n","    return optimizer_dict\n","\n","def update_learning_rate_decay(optimizer_dict, new_lr):\n","    for i in range(len(optimizer_dict)):\n","        optimizer_name = \"optimizer\" + str(i)\n","        optimizer_dict[optimizer_name].param_groups[0][\"lr\"] = new_lr\n","    return optimizer_dict\n","\n","# Model architectures\n","class Net2nn(nn.Module):\n","    def __init__(self):\n","        super(Net2nn, self).__init__()\n","        self.fc1 = nn.Linear(784, 200)\n","        self.fc2 = nn.Linear(200, 200)\n","        self.fc3 = nn.Linear(200, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","class Netcnn(nn.Module):\n","    def __init__(self):\n","        super(Netcnn, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 5)\n","        self.conv2 = nn.Conv2d(32, 64, 5)\n","        self.fc1 = nn.Linear(64 * 4 * 4, 512)\n","        self.fc2 = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = x.view(-1, 64 * 4 * 4)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","\n","        return x\n","\n","\n","\n","class Netcnn_cifar(nn.Module):\n","    def __init__(self):\n","        super(Netcnn_cifar, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3)\n","        self.conv2 = nn.Conv2d(32, 64, 3)\n","        self.conv3 = nn.Conv2d(64, 64, 3)\n","        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv3(x))\n","        x = x.view(-1, 64 * 4 * 4)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","\n","        return x\n","\n","\n","class Cifar10CNN(nn.Module):\n","\n","    def __init__(self):\n","        super(Cifar10CNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n","\n","\n","        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n","\n","\n","        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n","\n","\n","        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n","        # self.dropout1 = nn.Dropout()\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","\n","\n","        x = F.relu(self.conv3(x))\n","        x = F.relu(self.conv4(x))\n","        x = F.max_pool2d(x, 2)\n","\n","        x = F.relu(self.conv5(x))\n","        x = F.relu(self.conv6(x))\n","        x = F.max_pool2d(x, 2)\n","\n","        x = x.view(-1, 128 * 4 * 4)\n","        x = F.relu(self.fc1(x))\n","        # x = self.dropout1(x)\n","        x = self.fc2(x)\n","        return x\n","\n","\n","class Net_fashion(nn.Module):\n","    def __init__(self):\n","        super(Net_fashion, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n","        self.fc1 = nn.Linear(64 * 7 * 7, 500)\n","        self.fc2 = nn.Linear(500, 10)\n","\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.max_pool2d(x, 2)\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = x.view(-1, 64 * 7 * 7)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","\n","        return x\n","\n","\n","# Contents of train_nodes.py\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torch.utils.data import TensorDataset\n","from torchvision import models\n","from torchvision import transforms\n","from statistics import NormalDist\n","from scipy import stats\n","\n","\n","def train(model, train_loader, criterion, optimizer, device):\n","    model.train()\n","    train_loss = 0.0\n","    correct = 0\n","\n","    for data, target in train_loader:\n","        data, target = data.to(device), target.to(device)\n","        output = model(data)\n","        loss = criterion(output, target)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        prediction = output.argmax(dim=1, keepdim=True)\n","        correct += prediction.eq(target.view_as(prediction)).sum().item()\n","\n","    return train_loss / len(train_loader), correct / len(train_loader.dataset)\n","\n","def train_with_clipping(model, train_loader, criterion, optimizer, device, clipping=True, clipping_threshold=10):\n","    model.train()\n","    train_loss = 0.0\n","    correct = 0\n","\n","    for data, target in train_loader:\n","        data, target = data.to(device), target.to(device)\n","        output = model(data)\n","        loss = criterion(output, target)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        if clipping:\n","            torch.nn.utils.clip_grad_value_(model.parameters(), clipping_threshold)\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        prediction = output.argmax(dim=1, keepdim=True)\n","        correct += prediction.eq(target.view_as(prediction)).sum().item()\n","\n","    return train_loss / len(train_loader), correct / len(train_loader.dataset)\n","\n","\n","def train_with_augmentation(model, train_loader, criterion, optimizer, device, clipping, clipping_threshold=10, use_augmentation=False, augment=None ):\n","    model.train()\n","    train_loss = 0.0\n","    correct = 0\n","\n","    for data, target in train_loader:\n","        data, target = data.to(device), target.to(device)\n","\n","        if use_augmentation:\n","            data = augment(data)\n","\n","        output = model(data)\n","        loss = criterion(output, target)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        if clipping:\n","            torch.nn.utils.clip_grad_value_(model.parameters(), clipping_threshold)\n","\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        prediction = output.argmax(dim=1, keepdim=True)\n","        correct += prediction.eq(target.view_as(prediction)).sum().item()\n","\n","    return train_loss / len(train_loader), correct / len(train_loader.dataset)\n","\n","\n","def validation(model, test_loader, criterion, device):\n","    model.eval()\n","    test_loss = 0.0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","\n","            test_loss += criterion(output, target).item()\n","            prediction = output.argmax(dim=1, keepdim=True)\n","            correct += prediction.eq(target.view_as(prediction)).sum().item()\n","\n","    test_loss /= len(test_loader)\n","    correct /= len(test_loader.dataset)\n","\n","    return (test_loss, correct)\n","\n","\n","def get_model_names(model_dict):\n","    name_of_models = list(model_dict.keys())\n","    return name_of_models\n","\n","\n","def get_optimizer_names(optimizer_dict):\n","    name_of_optimizers = list(optimizer_dict.keys())\n","    return name_of_optimizers\n","\n","\n","def get_criterion_names(criterion_dict):\n","    name_of_criterions = list(criterion_dict.keys())\n","    return name_of_criterions\n","\n","\n","def get_x_train_sets_names(x_train_dict):\n","    name_of_x_train_sets = list(x_train_dict.keys())\n","    return name_of_x_train_sets\n","\n","\n","def get_y_train_sets_names(y_train_dict):\n","    name_of_y_train_sets = list(y_train_dict.keys())\n","    return name_of_y_train_sets\n","\n","\n","def get_x_valid_sets_names(x_valid_dict):\n","    name_of_x_valid_sets = list(x_valid_dict.keys())\n","    return name_of_x_valid_sets\n","\n","\n","def get_y_valid_sets_names(y_valid_dict):\n","    name_of_y_valid_sets = list(y_valid_dict.keys())\n","    return name_of_y_valid_sets\n","\n","\n","def get_x_test_sets_names(x_test_dict):\n","    name_of_x_test_sets = list(x_test_dict.keys())\n","    return name_of_x_test_sets\n","\n","\n","def get_y_test_sets_names(y_test_dict):\n","    name_of_y_test_sets = list(y_test_dict.keys())\n","    return name_of_y_test_sets\n","\n","\n","def create_model_optimizer_criterion_dict_for_mnist(number_of_samples, learning_rate, momentum, device, is_cnn=False, weight_decay=0):\n","    model_dict = dict()\n","    optimizer_dict = dict()\n","    criterion_dict = dict()\n","\n","    for i in range(number_of_samples):\n","        model_name = \"model\" + str(i)\n","        if is_cnn:\n","            model_info = Netcnn()\n","        else:\n","            model_info = Net2nn()\n","        model_info = model_info.to(device)\n","        model_dict.update({model_name: model_info})\n","\n","        optimizer_name = \"optimizer\" + str(i)\n","        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n","        optimizer_dict.update({optimizer_name: optimizer_info})\n","\n","        criterion_name = \"criterion\" + str(i)\n","        criterion_info = nn.CrossEntropyLoss()\n","        criterion_dict.update({criterion_name: criterion_info})\n","\n","    return model_dict, optimizer_dict, criterion_dict\n","\n","\n","def create_model_optimizer_criterion_dict_for_cifar_net(number_of_samples, learning_rate, momentum, device,\n","                                                        weight_decay=0):\n","    model_dict = dict()\n","    optimizer_dict = dict()\n","    criterion_dict = dict()\n","\n","    for i in range(number_of_samples):\n","        model_name = \"model\" + str(i)\n","\n","        model_info = Netcnn_cifar()\n","\n","        model_info = model_info.to(device)\n","        model_dict.update({model_name: model_info})\n","\n","        optimizer_name = \"optimizer\" + str(i)\n","        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n","        optimizer_dict.update({optimizer_name: optimizer_info})\n","\n","        criterion_name = \"criterion\" + str(i)\n","        criterion_info = nn.CrossEntropyLoss()\n","        criterion_dict.update({criterion_name: criterion_info})\n","\n","    return model_dict, optimizer_dict, criterion_dict\n","\n","def create_model_optimizer_criterion_dict_for_cifar_cnn(number_of_samples, learning_rate, momentum, device,\n","                                                        weight_decay=0):\n","    model_dict = dict()\n","    optimizer_dict = dict()\n","    criterion_dict = dict()\n","\n","    for i in range(number_of_samples):\n","        model_name = \"model\" + str(i)\n","\n","        model_info = Cifar10CNN()\n","\n","        model_info = model_info.to(device)\n","        model_dict.update({model_name: model_info})\n","\n","        optimizer_name = \"optimizer\" + str(i)\n","        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum,\n","                                         weight_decay=weight_decay)\n","        optimizer_dict.update({optimizer_name: optimizer_info})\n","\n","        criterion_name = \"criterion\" + str(i)\n","        criterion_info = nn.CrossEntropyLoss()\n","        criterion_dict.update({criterion_name: criterion_info})\n","\n","    return model_dict, optimizer_dict, criterion_dict\n","\n","def create_model_optimizer_criterion_dict_for_fashion_mnist(number_of_samples, learning_rate, momentum, device, weight_decay=0):\n","    model_dict = dict()\n","    optimizer_dict = dict()\n","    criterion_dict = dict()\n","\n","    for i in range(number_of_samples):\n","        model_name = \"model\" + str(i)\n","\n","        model_info = Net_fashion()\n","        model_info = model_info.to(device)\n","        model_dict.update({model_name: model_info})\n","\n","        optimizer_name = \"optimizer\" + str(i)\n","        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n","        optimizer_dict.update({optimizer_name: optimizer_info})\n","\n","        criterion_name = \"criterion\" + str(i)\n","        criterion_info = nn.CrossEntropyLoss()\n","        criterion_dict.update({criterion_name: criterion_info})\n","\n","    return model_dict, optimizer_dict, criterion_dict\n","\n","\n","def create_model_optimizer_criterion_dict_for_cifar_resnet(number_of_samples, learning_rate, momentum, device,\n","                                                           weight_decay=0):\n","    model_dict = dict()\n","    optimizer_dict = dict()\n","    criterion_dict = dict()\n","\n","    for i in range(number_of_samples):\n","        model_name = \"model\" + str(i)\n","\n","        model_info = models.resnet18(num_classes=10)\n","\n","        model_info = model_info.to(device)\n","        model_dict.update({model_name: model_info})\n","\n","        optimizer_name = \"optimizer\" + str(i)\n","        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum,\n","                                         weight_decay=weight_decay)\n","        optimizer_dict.update({optimizer_name: optimizer_info})\n","\n","        criterion_name = \"criterion\" + str(i)\n","        criterion_info = nn.CrossEntropyLoss()\n","        criterion_dict.update({criterion_name: criterion_info})\n","\n","    return model_dict, optimizer_dict, criterion_dict\n","\n","\n","def send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_samples):\n","    name_of_models = list(model_dict.keys())\n","    main_model_param_data_list = list(main_model.parameters())\n","    with torch.no_grad():\n","        for i in range(number_of_samples):\n","            sample_param_data_list = list(model_dict[name_of_models[i]].parameters())\n","            for j in range(len(main_model_param_data_list)):\n","                sample_param_data_list[j].data = main_model_param_data_list[j].data.clone()\n","    return model_dict\n","\n","\n","def compare_local_and_merged_model_performance(number_of_samples, x_test_dict, y_test_dict,\n","                                               batch_size, model_dict, criterion_dict, main_model,\n","                                               main_criterion, device):\n","    accuracy_table = pd.DataFrame(data=np.zeros((number_of_samples, 3)),\n","                                  columns=[\"sample\", \"local_ind_model\", \"merged_main_model\"])\n","\n","    name_of_x_test_sets = list(x_test_dict.keys())\n","    name_of_y_test_sets = list(y_test_dict.keys())\n","\n","    name_of_models = list(model_dict.keys())\n","    name_of_criterions = list(criterion_dict.keys())\n","\n","    for i in range(number_of_samples):\n","        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n","        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n","\n","        model = model_dict[name_of_models[i]]\n","        criterion = criterion_dict[name_of_criterions[i]]\n","\n","        individual_loss, individual_accuracy = validation(model, test_dl, criterion, device)\n","        main_loss, main_accuracy = validation(main_model, test_dl, main_criterion, device)\n","\n","        accuracy_table.loc[i, \"sample\"] = \"sample \" + str(i)\n","        accuracy_table.loc[i, \"local_ind_model\"] = individual_accuracy\n","        accuracy_table.loc[i, \"merged_main_model\"] = main_accuracy\n","\n","    return accuracy_table\n","\n","\n","def start_train_end_node_process_without_print(number_of_samples, x_train_dict, y_train_dict, x_test_dict, y_test_dict,\n","                                               batch_size, model_dict, criterion_dict, optimizer_dict, numEpoch,\n","                                               device):\n","    name_of_x_train_sets = get_x_train_sets_names(x_train_dict)\n","    name_of_y_train_sets = get_y_train_sets_names(y_train_dict)\n","    name_of_x_test_sets = get_x_test_sets_names(x_test_dict)\n","    name_of_y_test_sets = get_y_test_sets_names(y_test_dict)\n","    name_of_models = get_model_names(model_dict)\n","    name_of_criterions = get_criterion_names(criterion_dict)\n","    name_of_optimizers = get_optimizer_names(optimizer_dict)\n","\n","    for i in range(number_of_samples):\n","\n","        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n","        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","\n","        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n","        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n","\n","        model = model_dict[name_of_models[i]]\n","\n","        criterion = criterion_dict[name_of_criterions[i]]\n","        optimizer = optimizer_dict[name_of_optimizers[i]]\n","\n","        for epoch in range(numEpoch):\n","            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer, device)\n","            test_loss, test_accuracy = validation(model, test_dl, criterion, device)\n","\n","def start_train_end_node_process_with_cliiping(number_of_samples, x_train_dict, y_train_dict, x_test_dict, y_test_dict,\n","                                               batch_size, model_dict, criterion_dict, optimizer_dict, numEpoch,\n","                                               device, clipping=True, clipping_threshold=10):\n","    name_of_x_train_sets = get_x_train_sets_names(x_train_dict)\n","    name_of_y_train_sets = get_y_train_sets_names(y_train_dict)\n","    name_of_x_test_sets = get_x_test_sets_names(x_test_dict)\n","    name_of_y_test_sets = get_y_test_sets_names(y_test_dict)\n","    name_of_models = get_model_names(model_dict)\n","    name_of_criterions = get_criterion_names(criterion_dict)\n","    name_of_optimizers = get_optimizer_names(optimizer_dict)\n","\n","    for i in range(number_of_samples):\n","\n","        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n","        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","\n","        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n","        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n","\n","        model = model_dict[name_of_models[i]]\n","\n","        criterion = criterion_dict[name_of_criterions[i]]\n","        optimizer = optimizer_dict[name_of_optimizers[i]]\n","\n","        for epoch in range(numEpoch):\n","            train_loss, train_accuracy = train_with_clipping(model, train_dl, criterion, optimizer, device, clipping, clipping_threshold)\n","\n","            test_loss, test_accuracy = validation(model, test_dl, criterion, device)\n","\n","\n","\n","def start_train_end_node_process_cifar(number_of_samples, x_train_dict, y_train_dict, x_test_dict, y_test_dict,\n","                                       batch_size, model_dict, criterion_dict, optimizer_dict, numEpoch,\n","                                       device,clipping=False, clipping_threshold =10):\n","    name_of_x_train_sets = get_x_train_sets_names(x_train_dict)\n","    name_of_y_train_sets = get_y_train_sets_names(y_train_dict)\n","    name_of_x_test_sets = get_x_test_sets_names(x_test_dict)\n","    name_of_y_test_sets = get_y_test_sets_names(y_test_dict)\n","    name_of_models = get_model_names(model_dict)\n","    name_of_criterions = get_criterion_names(criterion_dict)\n","    name_of_optimizers = get_optimizer_names(optimizer_dict)\n","\n","    transform_augment = transforms.Compose(\n","        [\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomCrop((32, 32), padding=4)])\n","\n","    for i in range(number_of_samples):\n","\n","        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n","        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","\n","        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n","        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n","\n","        model = model_dict[name_of_models[i]]\n","        criterion = criterion_dict[name_of_criterions[i]]\n","        optimizer = optimizer_dict[name_of_optimizers[i]]\n","\n","        for epoch in range(numEpoch):\n","            train_loss, train_accuracy = train_with_augmentation(model, train_dl, criterion, optimizer, device,\n","                                                                 clipping=clipping,\n","                                                                 clipping_threshold=clipping_threshold,\n","                                                                 use_augmentation=True, augment=transform_augment)\n","\n","            test_loss, test_accuracy = validation(model, test_dl, criterion, device)\n","\n","\n","##########################################\n","\n","def start_train_end_node_process_byzantine_for_cifar_with_augmentation(number_of_samples, x_train_dict, y_train_dict, x_test_dict, y_test_dict,\n","                                               batch_size, model_dict, criterion_dict, optimizer_dict, numEpoch, byzantine_node_list,\n","                                            byzantine_mean, byzantine_std, device, clipping=False, clipping_threshold =10, iteration_byzantine_seed=None ):\n","\n","    name_of_x_train_sets = get_x_train_sets_names(x_train_dict)\n","    name_of_y_train_sets = get_y_train_sets_names(y_train_dict)\n","    name_of_x_test_sets = get_x_test_sets_names(x_test_dict)\n","    name_of_y_test_sets = get_y_test_sets_names(y_test_dict)\n","    name_of_models = get_model_names(model_dict)\n","    name_of_criterions = get_criterion_names(criterion_dict)\n","    name_of_optimizers = get_optimizer_names(optimizer_dict)\n","\n","    transform_augment = transforms.Compose(\n","        [\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomCrop((32, 32), padding=4)])\n","\n","\n","\n","    trusted_nodes=  np.array(list(set(np.arange(number_of_samples)) - set(byzantine_node_list)), dtype=int)\n","\n","    ## STANDARD LOCAL MODEL TRAİNİNG PROCESS FOR TRUSTED NODES\n","    for i in trusted_nodes:\n","\n","        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n","        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","\n","        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n","        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n","\n","        model = model_dict[name_of_models[i]]\n","        criterion = criterion_dict[name_of_criterions[i]]\n","        optimizer = optimizer_dict[name_of_optimizers[i]]\n","\n","        for epoch in range(numEpoch):\n","            train_loss, train_accuracy = train_with_augmentation(model, train_dl, criterion, optimizer, device, clipping=clipping, clipping_threshold=clipping_threshold,\n","                                                                 use_augmentation=True, augment=transform_augment)\n","            test_loss, test_accuracy = validation(model, test_dl, criterion, device)\n","\n","    with torch.no_grad():\n","\n","        for j in byzantine_node_list:\n","\n","            hostile_node_param_data_list = list(model_dict[name_of_models[j]].parameters())\n","\n","            for k in range(len(hostile_node_param_data_list)):\n","                np.random.seed(iteration_byzantine_seed)\n","                hostile_node_param_data_list[k].data = torch.tensor(np.random.normal(byzantine_mean,byzantine_std, hostile_node_param_data_list[k].data.shape ), dtype=torch.float32, device=device)\n","\n","            model_dict[name_of_models[j]].float()\n","\n","\n","###############################################\n","\n","def start_train_end_node_process_byzantine(number_of_samples, x_train_dict, y_train_dict, x_test_dict, y_test_dict,\n","                                               batch_size, model_dict, criterion_dict, optimizer_dict,\n","                                               numEpoch, byzantine_node_list, byzantine_mean, byzantine_std, device, iteration_byzantine_seed=None ):\n","    name_of_x_train_sets = get_x_train_sets_names(x_train_dict)\n","    name_of_y_train_sets = get_y_train_sets_names(y_train_dict)\n","    name_of_x_test_sets = get_x_test_sets_names(x_test_dict)\n","    name_of_y_test_sets = get_y_test_sets_names(y_test_dict)\n","    name_of_models = get_model_names(model_dict)\n","    name_of_criterions = get_criterion_names(criterion_dict)\n","    name_of_optimizers = get_optimizer_names(optimizer_dict)\n","\n","\n","\n","    trusted_nodes=  np.array(list(set(np.arange(number_of_samples)) - set(byzantine_node_list)), dtype=int)\n","\n","    ## STANDARD LOCAL MODEL TRAİNİNG PROCESS FOR TRUSTED NODES\n","    for i in trusted_nodes:\n","\n","        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n","        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","\n","        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n","        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n","\n","        model = model_dict[name_of_models[i]]\n","        criterion = criterion_dict[name_of_criterions[i]]\n","        optimizer = optimizer_dict[name_of_optimizers[i]]\n","\n","        for epoch in range(numEpoch):\n","            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer, device)\n","            test_loss, test_accuracy = validation(model, test_dl, criterion, device)\n","\n","\n","    with torch.no_grad():\n","        for j in byzantine_node_list:\n","            hostile_node_param_data_list = list(model_dict[name_of_models[j]].parameters())\n","\n","            for k in range(len(hostile_node_param_data_list)):\n","                np.random.seed(iteration_byzantine_seed)\n","                hostile_node_param_data_list[k].data = torch.tensor(np.random.normal(byzantine_mean,byzantine_std, hostile_node_param_data_list[k].data.shape ), dtype=torch.float32, device=device)\n","\n","            model_dict[name_of_models[j]].float()\n","\n","\n","################################################\n","\n","def calculate_euclidean_distances(main_model, model_dict):\n","    calculated_parameter_names = []\n","\n","    for parameters in main_model.named_parameters():  ## bias dataları için distance hesaplamıyorum\n","        if \"bias\" not in parameters[0]:\n","            calculated_parameter_names.append(parameters[0])\n","\n","    columns = [\"model\"] + calculated_parameter_names\n","    distances = pd.DataFrame(columns=columns)\n","    model_names = list(model_dict.keys())\n","\n","    main_model_weight_dict = {}\n","    for parameter in main_model.named_parameters():\n","        name = parameter[0]\n","        weight_info = parameter[1]\n","        main_model_weight_dict.update({name: weight_info})\n","\n","    with torch.no_grad():\n","        for i in range(len(model_names)):\n","            distances.loc[i, \"model\"] = model_names[i]\n","            sample_node_parameter_list = list(model_dict[model_names[i]].named_parameters())\n","            for j in sample_node_parameter_list:\n","                if j[0] in calculated_parameter_names:\n","                    distances.loc[i, j[0]] = round(\n","                        np.linalg.norm(main_model_weight_dict[j[0]].cpu().data - j[1].cpu().data), 4)\n","\n","    return distances\n","\n","\n","def calculate_lower_and_upper_limit(data, factor):\n","    quantiles = data.quantile(q=[0.25, 0.50, 0.75]).values\n","    q1 = quantiles[0]\n","    q2 = quantiles[1]\n","    q3 = quantiles[2]\n","    iqr = q3 - q1\n","    lower_limit = q1 - factor * iqr\n","    upper_limit = q3 + factor * iqr\n","    return lower_limit, upper_limit\n","\n","\n","def get_outlier_situation_and_thresholds_for_layers(distances, factor=1.5):\n","    layers = list(distances.columns)\n","    layers.remove(\"model\")\n","    threshold_columns = []\n","    for layer in layers:\n","        threshold_columns.append((layer + \"_lower\"))\n","        threshold_columns.append((layer + \"_upper\"))\n","    thresholds = pd.DataFrame(columns=threshold_columns)\n","\n","    include_calculation_result = True\n","    for layer in layers:\n","        data = distances[layer]\n","        lower, upper = calculate_lower_and_upper_limit(data, factor)\n","        lower_name = layer + \"_lower\"\n","        upper_name = layer + \"_upper\"\n","        thresholds.loc[0, lower_name] = lower\n","        thresholds.loc[0, upper_name] = upper\n","        name = layer + \"_is_in_ci\"\n","\n","        distances[name] = (distances[layer] \u003e lower) \u0026 (distances[layer] \u003c upper)\n","        include_calculation_result = include_calculation_result \u0026 distances[name]\n","\n","    distances[\"include_calculation\"] = include_calculation_result\n","    return distances, thresholds\n","\n","\n","def compare_individual_models_on_only_one_label(model_dict, criterion_dict, x_just_dict, y_just_dict, batch_size,\n","                                                device):\n","    columns = [\"model_name\"]\n","    label_names = []\n","    for l in range(10):\n","        label_names.append(\"label\" + str(l))\n","        columns.append(\"label\" + str(l))\n","\n","    accuracy_rec = pd.DataFrame(data=np.zeros([10, 11]), columns=columns)\n","\n","    # x_just_dict, y_just_dict = create_just_data(x_test, y_test, x_just_name=\"x_test_just_\", y_just_name=\"y_test_just_\")\n","\n","    name_of_x_test_just_sets = list(x_just_dict.keys())\n","    name_of_y_test_just_sets = list(y_just_dict.keys())\n","    name_of_models = list(model_dict.keys())\n","    name_of_criterions = list(criterion_dict.keys())\n","\n","    for i in range(len(name_of_models)):\n","        model = model_dict[name_of_models[i]]\n","        criterion = criterion_dict[name_of_criterions[i]]\n","\n","        accuracy_rec.loc[i, \"model_name\"] = name_of_models[i]\n","\n","        for j in range(10):\n","            x_test_just = x_just_dict[name_of_x_test_just_sets[j]]\n","            y_test_just = y_just_dict[name_of_y_test_just_sets[j]]\n","\n","            test_ds_just = TensorDataset(x_test_just, y_test_just)\n","            test_dl_just = DataLoader(test_ds_just, batch_size=batch_size * 2)\n","\n","            test_loss, test_accuracy = validation(model, test_dl_just, criterion, device)\n","\n","            accuracy_rec.loc[i, label_names[j]] = test_accuracy\n","    #             print( name_of_models[i], \"\u003e\u003e\" ,j, \" tahmin etmesi: {:7.4f}\".format(test_accuracy))\n","    #         print(\"******************\")\n","    return accuracy_rec\n","\n","\n","def get_averaged_weights_faster(model_dict, device):\n","    name_of_models = list(model_dict.keys())\n","    parameters = list(model_dict[name_of_models[0]].named_parameters())\n","    ##named_parameters layer adını ve datayı tuple olarak dönderiyor\n","    ##parameters sadece datayı dönderiyor\n","\n","    weight_dict = dict()\n","    for k in range(len(parameters)):\n","        name = parameters[k][0]\n","        w_shape = list(parameters[k][1].shape)\n","        w_shape.insert(0, len(model_dict))\n","        weight_info = torch.zeros(w_shape, device=device)\n","        weight_dict.update({name: weight_info})\n","\n","    weight_names_list = list(weight_dict.keys())\n","    with torch.no_grad():\n","        for i in range(len(model_dict)):\n","            sample_param_data_list = list(model_dict[name_of_models[i]].parameters())\n","            for j in range(len(weight_names_list)):\n","                weight_dict[weight_names_list[j]][i,] = sample_param_data_list[j].data.clone()\n","\n","        mean_weight_array = []\n","        for m in range(len(weight_names_list)):\n","            mean_weight_array.append(torch.mean(weight_dict[weight_names_list[m]], 0))\n","\n","    return mean_weight_array\n","\n","\n","def set_averaged_weights_as_main_model_weights_and_update_main_model(main_model, model_dict, device):\n","    mean_weight_array = get_averaged_weights_faster(model_dict, device)\n","    main_model_param_data_list = list(main_model.parameters())\n","    with torch.no_grad():\n","        for j in range(len(main_model_param_data_list)):\n","            main_model_param_data_list[j].data = mean_weight_array[j]\n","    return main_model\n","\n","\n","def get_coordinate_wise_median_of_weights(model_dict, device):\n","    name_of_models = list(model_dict.keys())\n","    parameters = list(model_dict[name_of_models[0]].named_parameters())\n","    ##named_parameters layer adını ve datayı tuple olarak dönderiyor\n","    ##parameters sadece datayı dönderiyor\n","\n","    weight_dict = dict()\n","    for k in range(len(parameters)):\n","        name = parameters[k][0]\n","        w_shape = list(parameters[k][1].shape)\n","        w_shape.insert(0, len(model_dict))\n","        weight_info = torch.zeros(w_shape, device=device)\n","        weight_dict.update({name: weight_info})\n","\n","    weight_names_list = list(weight_dict.keys())\n","    with torch.no_grad():\n","        for i in range(len(model_dict)):\n","            sample_param_data_list = list(model_dict[name_of_models[i]].parameters())\n","            for j in range(len(weight_names_list)):\n","                weight_dict[weight_names_list[j]][i,] = sample_param_data_list[j].data.clone()\n","\n","        median_weight_array = []\n","        for m in range(len(weight_names_list)):\n","            median_weight_array.append(torch.median(weight_dict[weight_names_list[m]], 0).values)\n","\n","    return median_weight_array\n","\n","def set_coordinatewise_med_weights_as_main_model_weights_and_update_main_model(main_model, model_dict, device):\n","    median_weight_array = get_coordinate_wise_median_of_weights(model_dict, device)\n","    main_model_param_data_list = list(main_model.parameters())\n","    with torch.no_grad():\n","        for j in range(len(main_model_param_data_list)):\n","            main_model_param_data_list[j].data = median_weight_array[j]\n","    return main_model\n","\n","\n","\n","\n","\n","\n","\n","\n","def get_averaged_weights_without_outliers_strict_condition(model_dict, iteration_distance, device):\n","    chosen_clients = iteration_distance[iteration_distance[\"include_calculation\"] == True].index\n","    name_of_models = list(model_dict.keys())\n","    parameters = list(model_dict[name_of_models[0]].named_parameters())\n","\n","    ### mesela conv 1 için zeros [chosen client kadar, 32, 1, 5, 5] atanıyor bunları doldurup mean alacağız\n","    weight_dict = dict()\n","    for k in range(len(parameters)):\n","        name = parameters[k][0]\n","        w_shape = list(parameters[k][1].shape)\n","        w_shape.insert(0, len(chosen_clients))\n","        weight_info = torch.zeros(w_shape, device=device)\n","        weight_dict.update({name: weight_info})\n","\n","    weight_names_list = list(weight_dict.keys())\n","    with torch.no_grad():\n","        for i in range(len(chosen_clients)):\n","            sample_param_data_list = list(model_dict[name_of_models[chosen_clients[i]]].parameters())\n","            for j in range(len(weight_names_list)):\n","                weight_dict[weight_names_list[j]][i,] = sample_param_data_list[j].data.clone()\n","\n","        mean_weight_array = []\n","        for m in range(len(weight_names_list)):\n","            mean_weight_array.append(torch.mean(weight_dict[weight_names_list[m]], 0))\n","\n","    return mean_weight_array\n","\n","\n","def strict_condition_without_outliers_set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,\n","                                                                                                       model_dict,\n","                                                                                                       iteration_distance,\n","                                                                                                       device):\n","    mean_weight_array = get_averaged_weights_without_outliers_strict_condition(model_dict, iteration_distance, device)\n","    main_model_param_data_list = list(main_model.parameters())\n","    with torch.no_grad():\n","        for j in range(len(main_model_param_data_list)):\n","            main_model_param_data_list[j].data = mean_weight_array[j]\n","    return main_model\n","\n","## they do not perform any training and send same parameters that are received at the beginning at the fl round\n","def start_train_end_node_process_with_anticatalysts(number_of_samples, x_train_dict, y_train_dict, x_test_dict, y_test_dict,\n","                                                    batch_size, model_dict, criterion_dict, optimizer_dict,\n","                                                    numEpoch, byzantine_node_list, device):\n","    name_of_x_train_sets = get_x_train_sets_names(x_train_dict)\n","    name_of_y_train_sets = get_y_train_sets_names(y_train_dict)\n","    name_of_x_test_sets = get_x_test_sets_names(x_test_dict)\n","    name_of_y_test_sets = get_y_test_sets_names(y_test_dict)\n","    name_of_models = get_model_names(model_dict)\n","    name_of_criterions = get_criterion_names(criterion_dict)\n","    name_of_optimizers = get_optimizer_names(optimizer_dict)\n","\n","\n","\n","    trusted_nodes=  np.array(list(set(np.arange(number_of_samples)) - set(byzantine_node_list)), dtype=int)\n","\n","    ## STANDARD LOCAL MODEL TRAİNİNG PROCESS FOR TRUSTED NODES\n","    for i in trusted_nodes:\n","\n","        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n","        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","\n","        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n","        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n","\n","        model = model_dict[name_of_models[i]]\n","        criterion = criterion_dict[name_of_criterions[i]]\n","        optimizer = optimizer_dict[name_of_optimizers[i]]\n","\n","        for epoch in range(numEpoch):\n","            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer, device)\n","            test_loss, test_accuracy = validation(model, test_dl, criterion, device)\n","\n","\n","######################################\n","#### a little is enough functions\n","def get_zscore_for_a_little_is_enough (number_of_samples,hostile_node_percentage):\n","#     from statistics import NormalDist is defined at the top\n","    malicious = int(number_of_samples * hostile_node_percentage)\n","    supporter = np.floor((number_of_samples / 2) + 1) - malicious\n","    area = (number_of_samples - malicious - supporter) / (number_of_samples - malicious)\n","    zscore = NormalDist().inv_cdf(area)\n","    return zscore\n","def get_byzantine_node_stats_for_a_little(model_dict,byzantine_node_list, device):\n","    name_of_models = []\n","    for node in byzantine_node_list:\n","        name_of_models.append(\"model\"+str(node))\n","    parameters = list(model_dict[name_of_models[0]].named_parameters())\n","    ##named_parameters layer adını ve datayı tuple olarak dönderiyor\n","    ##parameters sadece datayı dönderiyor\n","    weight_dict = dict()\n","    for k in range(len(parameters)):\n","        name = parameters[k][0]\n","        w_shape = list(parameters[k][1].shape)\n","        w_shape.insert(0, len(byzantine_node_list))\n","        weight_info = torch.zeros(w_shape, device=device)\n","        weight_dict.update({name: weight_info})\n","    weight_names_list = list(weight_dict.keys())\n","    with torch.no_grad():\n","        for i in range(len(byzantine_node_list)):\n","            sample_param_data_list = list(model_dict[name_of_models[i]].parameters())\n","            for j in range(len(weight_names_list)):\n","                weight_dict[weight_names_list[j]][i,] = sample_param_data_list[j].data.clone()\n","        mean_weight_array = []\n","        std_weight_array = []\n","        for m in range(len(weight_names_list)):\n","            mean_weight_array.append(torch.mean(weight_dict[weight_names_list[m]], 0))\n","            std_weight_array.append(torch.std(weight_dict[weight_names_list[m]], 0))\n","    return mean_weight_array,std_weight_array\n","def change_parameters_of_hostile_nodes(model_dict, byzantine_node_list,zscore, device):\n","    name_of_models = list(model_dict.keys())\n","    with torch.no_grad():\n","        mean_weight_array,std_weight_array = get_byzantine_node_stats_for_a_little(model_dict,byzantine_node_list, device=device)\n","        for j in byzantine_node_list:\n","            hostile_node_param_data_list = list(model_dict[name_of_models[j]].parameters())\n","            for k in range(len(hostile_node_param_data_list)):\n","                hostile_node_param_data_list[k].data= mean_weight_array[k]-std_weight_array[k]*zscore\n","            model_dict[name_of_models[j]].float()\n","    return model_dict\n","#####################################\n","def get_trimmed_mean(model_dict, hostile_node_percentage, device):\n","    name_of_models = list(model_dict.keys())\n","    parameters = list(model_dict[name_of_models[0]].named_parameters())\n","    weight_dict = dict()\n","    for k in range(len(parameters)):\n","        name = parameters[k][0]\n","        w_shape = list(parameters[k][1].shape)\n","        w_shape.insert(0, len(model_dict))\n","        weight_info = torch.zeros(w_shape, device=device)\n","        weight_dict.update({name: weight_info})\n","    weight_names_list = list(weight_dict.keys())\n","    with torch.no_grad():\n","        for i in range(len(model_dict)):\n","            sample_param_data_list = list(model_dict[name_of_models[i]].parameters())\n","            for j in range(len(weight_names_list)):\n","                weight_dict[weight_names_list[j]][i,] = sample_param_data_list[j].data.clone()\n","    mean_weight_array = []\n","    for m in range(len(weight_names_list)):\n","        layers_from_nodes = weight_dict[weight_names_list[m]]\n","        trim_layer_info=stats.trim_mean(layers_from_nodes.clone().cpu(), hostile_node_percentage, axis=0)\n","        mean_weight_array.append(trim_layer_info)\n","    return mean_weight_array\n","def set_trimmed_mean_weights_as_main_model_weights_and_update_main_model(main_model, model_dict, hostile_node_percentage, device):\n","    mean_weight_array = get_trimmed_mean(model_dict, hostile_node_percentage, device)\n","    main_model_param_data_list = list(main_model.parameters())\n","    with torch.no_grad():\n","        for j in range(len(main_model_param_data_list)):\n","                        main_model_param_data_list[j].data = torch.tensor(mean_weight_array[j], dtype=torch.float32, device=device)\n","    return main_model\n","######################################\n","# fang partial knowledge attack adaptation\n","def partial_knowledge_fang_ind(main_model, model_dict,byzantine_node_list, iteration_byzantine_seed, device):\n","    name_of_models = list(model_dict.keys())\n","    with torch.no_grad():\n","        mean_weight_array, std_weight_array = get_byzantine_node_stats_for_a_little(model_dict, byzantine_node_list,\n","                                                                                       device=device)\n","        main_model_param_data_list = list(main_model.parameters())\n","        for j in byzantine_node_list:\n","            hostile_node_param_data_list = list(model_dict[name_of_models[j]].parameters())\n","            for k in range(len(hostile_node_param_data_list)):\n","                original_shape = list(hostile_node_param_data_list[k].data.shape)\n","                data = np.zeros(original_shape)\n","                hostile_data = hostile_node_param_data_list[k].data.clone().data.cpu()\n","                main_model_data = main_model_param_data_list[k].data.clone().data.cpu()\n","                mean = mean_weight_array[k].clone().data.cpu()\n","                std = std_weight_array[k].clone().data.cpu()\n","                sign_matrix = (hostile_data \u003e main_model_data)\n","                np.random.seed(iteration_byzantine_seed) ## nodelar kendi mean stdlerine göre alıyor her experimentin x. roundı aynı gibi\n","                data[sign_matrix == True] = np.random.uniform(\n","                    low=mean[sign_matrix == True] - 4 * std[sign_matrix == True],\n","                    high=mean[sign_matrix == True] - 3 * std[sign_matrix == True])\n","                np.random.seed(iteration_byzantine_seed)\n","                data[sign_matrix == False] = np.random.uniform(\n","                    low=mean[sign_matrix == False] + 3 * std[sign_matrix == False],\n","                    high=mean[sign_matrix == False] + 4 * std[sign_matrix == False])\n","                hostile_node_param_data_list[k].data = torch.tensor(data,dtype=torch.float32, device=device)\n","            model_dict[name_of_models[j]].float()\n","    return model_dict\n","def partial_knowledge_fang_org(main_model, model_dict, byzantine_node_list, iteration_byzantine_seed, device):\n","    name_of_models = list(model_dict.keys())\n","    with torch.no_grad():\n","        mean_weight_array, std_weight_array = get_byzantine_node_stats_for_a_little(model_dict, byzantine_node_list,\n","                                                                                       device=device)\n","        main_model_param_data_list = list(main_model.parameters())\n","        organized = []\n","        for k in range(len(main_model_param_data_list)):\n","            original_shape = list(main_model_param_data_list[k].data.shape)\n","            data = np.zeros(original_shape)\n","            main_model_data = main_model_param_data_list[k].clone().data.cpu()\n","            mean = mean_weight_array[k].clone().data.cpu()\n","            std = std_weight_array[k].clone().data.cpu()\n","            sign_matrix = (mean \u003e main_model_data)\n","            np.random.seed(iteration_byzantine_seed)\n","            data[sign_matrix == True] = np.random.uniform(\n","                low=mean[sign_matrix == True] - 4 * std[sign_matrix == True],\n","                high=mean[sign_matrix == True] - 3 * std[sign_matrix == True])\n","            np.random.seed(iteration_byzantine_seed)\n","            data[sign_matrix == False] = np.random.uniform(\n","                low=mean[sign_matrix == False] + 3 * std[sign_matrix == False],\n","                high=mean[sign_matrix == False] + 4 * std[sign_matrix == False])\n","            organized.append(data)\n","    for b in byzantine_node_list:\n","        hostile_node_param_data_list = list(model_dict[name_of_models[b]].parameters())\n","        for m in range(len(hostile_node_param_data_list)):\n","            hostile_node_param_data_list[m].data = torch.tensor(organized[m], dtype=torch.float32, device=device)\n","        model_dict[name_of_models[b]].float()\n","    return model_dict\n","\n","# Contents of distribute_data.py\n","import numpy as np\n","import pandas as pd\n","import torch\n","import cv2\n","import os\n","import requests\n","import pickle\n","import gzip\n","import math\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","\n","\n","def load_mnist_data():\n","    DATA_PATH = Path(\"data\")\n","    PATH = DATA_PATH / \"mnist\"\n","\n","    PATH.mkdir(parents=True, exist_ok=True)\n","\n","    URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n","    FILENAME = \"mnist.pkl.gz\"\n","\n","    if not (PATH / FILENAME).exists():\n","        content = requests.get(URL + FILENAME).content\n","        (PATH / FILENAME).open(\"wb\").write(content)\n","\n","    with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n","        ((x_train, y_train), (x_valid, y_valid), (x_test, y_test)) = pickle.load(f, encoding=\"latin-1\")\n","\n","    return x_train, y_train, x_valid, y_valid, x_test, y_test\n","\n","\n","def load_cifar_data():\n","    transform = transforms.Compose(\n","        [\n","            transforms.ToTensor(),\n","         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                            download=True, transform=transform)\n","\n","    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                           download=True, transform=transform)\n","\n","    x_train = torch.zeros((50000, 3, 32, 32))\n","    y_train = torch.zeros(50000)\n","    ind_train = 0\n","    for data, output in trainset:\n","        x_train[ind_train, :, :, :] = data\n","        y_train[ind_train] = output\n","        ind_train = ind_train + 1\n","\n","    x_test = torch.zeros((10000, 3, 32, 32))\n","    y_test = torch.zeros(10000)\n","    ind_test = 0\n","    for data, output in testset:\n","        x_test[ind_test, :, :, :] = data\n","        y_test[ind_test] = output\n","        ind_test = ind_test + 1\n","\n","    y_train = y_train.type(torch.LongTensor)\n","    y_test = y_test.type(torch.LongTensor)\n","\n","    return x_train, y_train, x_test, y_test\n","\n","\n","\n","def show_grid_cifar(x_data,y_data, row,column):\n","    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","    fig, axes = plt.subplots(row,column,figsize=(8,8))\n","    for i in range(row):\n","        for j in range(column):\n","            num_index = np.random.randint(len(x_data))\n","            img=x_data[num_index,:,:,:]\n","            img = img / 2 + 0.5     # unnormalize\n","            npimg = img.numpy()\n","            npimg =np.transpose(npimg, (1, 2, 0))\n","            axes[i,j].imshow(npimg)\n","\n","            axes[i,j].axis(\"off\")\n","            axes[i,j].set_title(classes[int(y_data[num_index])])\n","    plt.show()\n","\n","def load_fashion_mnist_data():\n","    transform = transforms.Compose([transforms.ToTensor()])\n","\n","    trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","    testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n","\n","    x_train = trainset.data\n","    x_train = x_train / 255\n","    y_train = trainset.targets\n","\n","    x_test = testset.data\n","    x_test = x_test / 255\n","    y_test = testset.targets\n","\n","    return x_train, y_train, x_test, y_test\n","\n","\n","def show_grid_fashion_mnist(x_data, y_data, row, column):\n","    classes = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n","    fig, axes = plt.subplots(row, column, figsize=(8, 8))\n","    for i in range(row):\n","        for j in range(column):\n","            num_index = np.random.randint(len(x_data))\n","\n","            axes[i, j].imshow(x_data[num_index], cmap=\"gray\")\n","            axes[i, j].axis(\"off\")\n","            axes[i, j].set_title(classes[int(y_data[num_index])])\n","    plt.show()\n","\n","\n","def split_and_shuffle_labels(y_data, seed, amount):\n","    y_data = pd.DataFrame(y_data, columns=[\"labels\"])\n","    y_data[\"i\"] = np.arange(len(y_data))\n","    label_dict = dict()\n","    for i in range(10):\n","        var_name = \"label\" + str(i)\n","        label_info = y_data[y_data[\"labels\"] == i]\n","        np.random.seed(seed)\n","        label_info = np.random.permutation(label_info)\n","        label_info = label_info[0:amount]\n","        label_info = pd.DataFrame(label_info, columns=[\"labels\", \"i\"])\n","        label_dict.update({var_name: label_info})\n","    return label_dict\n","\n","\n","\n","def get_info_for_distribute_non_iid_with_different_n_and_amount(number_of_samples, n, amount, seed, min_n_each_node=2):\n","    node_label_info = np.ones([number_of_samples, n]) * -1\n","    columns = []\n","    for j in range(n):\n","        columns.append(\"s\" + str(j))\n","    node_label_info = pd.DataFrame(node_label_info, columns=columns, dtype=int)\n","\n","    np.random.seed(seed)\n","    seeds = np.random.choice(number_of_samples * n * 5, size=number_of_samples, replace=False)\n","    for i in range(number_of_samples):\n","        np.random.seed(seeds[i])\n","        how_many_label_created = np.random.randint(\n","            n + 1 - min_n_each_node) + min_n_each_node  ## ensures at least one label is created by default\n","        which_labels = np.random.choice(10, size=how_many_label_created, replace=False)\n","        node_label_info.iloc[i, 0:len(which_labels)] = which_labels\n","\n","    #################################\n","    #################################\n","\n","    total_label_occurences = pd.DataFrame()\n","    for m in range(10):\n","\n","        total_label_occurences.loc[0, m] = int(np.sum(node_label_info.values == m))\n","        if total_label_occurences.loc[0, m] == 0:\n","            total_label_occurences.loc[1, m] = 0\n","        else:\n","            total_label_occurences.loc[1, m] = int(amount / np.sum(node_label_info.values == m))\n","    total_label_occurences = total_label_occurences.astype('int32')\n","\n","    ##################################\n","    ##################################\n","\n","    amount_info_table = pd.DataFrame(np.zeros([number_of_samples, n]), dtype=int)\n","    for a in range(number_of_samples):\n","        for b in range(n):\n","            if node_label_info.iloc[a, b] == -1:\n","                amount_info_table.iloc[a, b] = 0\n","            else:\n","                amount_info_table.iloc[a, b] = total_label_occurences.iloc[1, node_label_info.iloc[a, b]]\n","\n","    return node_label_info, total_label_occurences, amount_info_table\n","\n","\n","def distribute_mnist_data_to_participants(label_dict, amount, number_of_samples, n,\n","                                          x_data, y_data, x_name, y_name, node_label_info,\n","                                          amount_info_table, is_cnn=False):\n","    label_names = list(label_dict)\n","    label_dict_data = pd.DataFrame(columns=[\"labels\", \"i\"])\n","\n","    for a in label_names:\n","        data = pd.DataFrame.from_dict(label_dict[a])\n","        label_dict_data = pd.concat([label_dict_data, data], ignore_index=True)\n","\n","    index_counter = pd.DataFrame(label_names, columns=[\"labels\"])\n","    index_counter[\"start\"] = np.ones(10, dtype=int) * np.arange(10) * amount\n","    index_counter[\"end\"] = np.ones(10, dtype=int) * np.arange(10) * amount\n","\n","    x_data_dict = dict()\n","    y_data_dict = dict()\n","\n","    for i in range(number_of_samples):\n","        node_data_indices = pd.DataFrame()\n","\n","        xname = x_name + str(i)\n","        yname = y_name + str(i)\n","\n","        for j in range(n):\n","            label = node_label_info.iloc[i, j]\n","            if label != -1:\n","                label_amount = amount_info_table.iloc[i, j]\n","                index_counter.loc[label, \"end\"] = index_counter.loc[label, \"end\"] + label_amount\n","                node_data_indices = pd.concat([node_data_indices, label_dict_data.loc[\n","                                                                  index_counter.loc[label, \"start\"]:index_counter.loc[\n","                                                                                                        label, \"end\"] - 1,\n","                                                                  \"i\"]])\n","                index_counter.loc[label, \"start\"] = index_counter.loc[label, \"end\"]\n","\n","        x_info = x_data[node_data_indices.iloc[:, 0].reset_index(drop=True), :]\n","        if is_cnn:\n","            reshape_size = int(np.sqrt(x_info.shape[1]))\n","            x_info = x_info.view(-1, 1, reshape_size, reshape_size)\n","\n","        x_data_dict.update({xname: x_info})\n","\n","        y_info = y_data[node_data_indices.iloc[:, 0].reset_index(drop=True)]\n","        y_data_dict.update({yname: y_info})\n","\n","    return x_data_dict, y_data_dict\n","\n","\n","def distribute_fashion_data_to_participants(label_dict, amount, number_of_samples, n,\n","                                            x_data, y_data, x_name, y_name, node_label_info, amount_info_table):\n","    label_names = list(label_dict)\n","    label_dict_data = pd.DataFrame(columns=[\"labels\", \"i\"])\n","\n","    for a in label_names:\n","        data = pd.DataFrame.from_dict(label_dict[a])\n","        label_dict_data = pd.concat([label_dict_data, data], ignore_index=True)\n","\n","    index_counter = pd.DataFrame(label_names, columns=[\"labels\"])\n","    index_counter[\"start\"] = np.ones(10, dtype=int) * np.arange(10) * amount\n","    index_counter[\"end\"] = np.ones(10, dtype=int) * np.arange(10) * amount\n","\n","    x_data_dict = dict()\n","    y_data_dict = dict()\n","\n","    for i in range(number_of_samples):\n","        node_data_indices = pd.DataFrame()\n","\n","        xname = x_name + str(i)\n","        yname = y_name + str(i)\n","\n","        for j in range(n):\n","            label = node_label_info.iloc[i, j]\n","            if label != -1:\n","                label_amount = amount_info_table.iloc[i, j]\n","                index_counter.loc[label, \"end\"] = index_counter.loc[label, \"end\"] + label_amount\n","                node_data_indices = pd.concat([node_data_indices, label_dict_data.loc[\n","                                                                  index_counter.loc[label, \"start\"]:index_counter.loc[\n","                                                                                                        label, \"end\"] - 1,\n","                                                                  \"i\"]])\n","                #                 print(label, \", start:\", index_counter.loc[label,\"start\"], \", end:\", index_counter.loc[label,\"end\"] )\n","                index_counter.loc[label, \"start\"] = index_counter.loc[label, \"end\"]\n","\n","        x_info = x_data[node_data_indices.iloc[:, 0].reset_index(drop=True), :]\n","\n","        x_info = x_info.view(-1, 1, 28, 28)\n","        x_data_dict.update({xname: x_info})\n","\n","        y_info = y_data[node_data_indices.iloc[:, 0].reset_index(drop=True)]\n","        y_data_dict.update({yname: y_info})\n","\n","    return x_data_dict, y_data_dict\n","\n","\n","def distribute_cifar_data_to_participants(label_dict, amount, number_of_samples, n,\n","                                          x_data, y_data, x_name, y_name, node_label_info,\n","                                          amount_info_table):\n","    label_names = list(label_dict)\n","    label_dict_data = pd.DataFrame(columns=[\"labels\", \"i\"])\n","\n","    for a in label_names:\n","        data = pd.DataFrame.from_dict(label_dict[a])\n","        label_dict_data = pd.concat([label_dict_data, data], ignore_index=True)\n","\n","    index_counter = pd.DataFrame(label_names, columns=[\"labels\"])\n","    index_counter[\"start\"] = np.ones(10, dtype=int) * np.arange(10) * amount\n","    index_counter[\"end\"] = np.ones(10, dtype=int) * np.arange(10) * amount\n","\n","    x_data_dict = dict()\n","    y_data_dict = dict()\n","\n","    for i in range(number_of_samples):\n","        node_data_indices = pd.DataFrame()\n","\n","        xname = x_name + str(i)\n","        yname = y_name + str(i)\n","\n","        for j in range(n):\n","            label = node_label_info.iloc[i, j]\n","            if label != -1:\n","                label_amount = amount_info_table.iloc[i, j]\n","                index_counter.loc[label, \"end\"] = index_counter.loc[label, \"end\"] + label_amount\n","                node_data_indices = pd.concat([node_data_indices, label_dict_data.loc[\n","                                                                  index_counter.loc[label, \"start\"]:index_counter.loc[\n","                                                                                                        label, \"end\"] - 1,\n","                                                                  \"i\"]])\n","\n","                index_counter.loc[label, \"start\"] = index_counter.loc[label, \"end\"]\n","\n","        x_info = x_data[node_data_indices.iloc[:, 0].reset_index(drop=True), :]\n","\n","        x_data_dict.update({xname: x_info})\n","\n","        y_info = y_data[node_data_indices.iloc[:, 0].reset_index(drop=True)]\n","        y_data_dict.update({yname: y_info})\n","\n","    return x_data_dict, y_data_dict\n","\n","\n","def create_just_data(x_data, y_data, x_just_name, y_just_name):\n","    x_just_dict = dict()\n","    y_just_dict = dict()\n","\n","    for i in range(10):\n","        xname = x_just_name + str(i)\n","        x_info = x_data[y_data == i]\n","        x_just_dict.update({xname: x_info})\n","\n","        yname = y_just_name + str(i)\n","        y_info = y_data[y_data == i]\n","        y_just_dict.update({yname: y_info})\n","\n","    return x_just_dict, y_just_dict\n","\n","\n","def get_equal_size_test_data_from_each_label(x_test, y_test, min_amount=890):\n","    y_test_eq=pd.DataFrame(y_test, columns=[\"labels\"])\n","    y_test_eq[\"ind\"]=np.arange(len(y_test))\n","    hold=pd.DataFrame(columns=[\"labels\", \"ind\"])\n","    for i in range(10):\n","        hold=pd.concat([hold,y_test_eq[y_test_eq[\"labels\"]==i].iloc[0:min_amount,:] ])\n","    indices=np.array(hold[\"ind\"], dtype=int)\n","    x_test=x_test[indices, :]\n","    y_test=y_test[indices]\n","    return x_test, y_test\n","\n","\n","def choose_nodes_randomly_to_convert_hostile(hostile_node_percentage, number_of_samples, hostility_seed=90):\n","    nodes_list=[]\n","    np.random.seed(hostility_seed)\n","    nodes=np.random.choice(number_of_samples, size=int(number_of_samples*hostile_node_percentage), replace=False)\n","    for node in nodes:\n","        name=\"y_train\"+str(node)\n","        nodes_list.append(name)\n","    return nodes_list\n","\n","def convert_nodes_to_hostile(y_dict, nodes_list,\n","                             converter_dict={0:9,1:7, 2:5,3:8, 4:6, 5:2, 6:4, 7:1, 8:3, 9:0}):\n","    for node in nodes_list:\n","        original_data=y_dict[node]\n","        converted_data=np.ones(y_dict[node].shape, dtype=int)*-1\n","        labels_in_node=np.unique(original_data)\n","        for label in labels_in_node:\n","            converted_data[original_data==label]=converter_dict[label]\n","        converted_data=(torch.tensor(converted_data)).type(torch.LongTensor)\n","        y_dict.update({node:converted_data})\n","    return y_dict\n","\n","\n","\n","def create_different_converters_for_each_attacker(y_dict, nodes_list, converters_seed):\n","    converters = dict()\n","    np.random.seed(converters_seed)\n","    converter_seeds_array = np.random.choice(5000, size=len(nodes_list), replace=False)\n","\n","    for i in range(len(nodes_list)):\n","        unique_labels = np.unique(y_dict[nodes_list[i]])\n","        np.random.seed([converter_seeds_array[i]])\n","        subseeds = np.random.choice(1000, len(unique_labels), replace=False)\n","\n","        conv = dict()\n","        for j in range(len(unique_labels)):\n","            choose_from = np.delete(np.arange(10), unique_labels[j])\n","            np.random.seed(subseeds[j])\n","            chosen = np.random.choice(choose_from, replace=False)\n","            conv[unique_labels[j]] = chosen\n","        converters.update({nodes_list[i]: conv})\n","    return converters\n","\n","def convert_nodes_to_hostile_with_different_converters(y_dict, nodes_list, converters_seed=61):\n","    converters= create_different_converters_for_each_attacker(y_dict, nodes_list, converters_seed)\n","    y_dict_converted = y_dict.copy()\n","    for node in nodes_list:\n","        original_data=y_dict[node]\n","        converted_data=np.ones(y_dict[node].shape, dtype=int)*-1\n","        labels_in_node=np.unique(original_data)\n","        for label in labels_in_node:\n","            converted_data[original_data==label]=converters[node][label]\n","        converted_data=(torch.tensor(converted_data)).type(torch.LongTensor)\n","        y_dict_converted.update({node:converted_data})\n","    return y_dict_converted\n","\n","\n","def get_byzantine_node_list(hostile_node_percentage, number_of_samples, hostility_seed=90):\n","\n","    np.random.seed(hostility_seed)\n","    nodes=np.random.choice(number_of_samples, size=int(number_of_samples*hostile_node_percentage), replace=False)\n","    return nodes\n","\n","\n","#main Script\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device: \", device)\n","\n","number_of_samples = 100 #number of participants\n","\n","is_noniid = True\n","if is_noniid:\n","    n = 5\n","    min_n_each_node = 5\n","else:\n","    n = 10\n","    min_n_each_node = 10\n","\n","is_organized = True\n","hostile_node_percentage = 0.20 #malicious participant ratio\n","\n","iteration_num = 4 #number of communication rounds / changed 500 to 4\n","learning_rate = 0.0015\n","min_lr = 0.000010\n","lr_scheduler_factor =0.2\n","best_threshold = 0.0001\n","clipping=True\n","clipping_threshold =10\n","\n","weight_decay = 0.0001\n","numEpoch = 10\n","batch_size = 100\n","momentum = 0.9\n","\n","seed = 11\n","use_seed = 8\n","hostility_seed = 90\n","converters_seed = 51\n","\n","train_amount = 500 #changed 5000 to 500\n","test_amount = 1000\n","\n","\n","\n","\n","x_train, y_train, x_test, y_test = load_cifar_data()\n","\n","##train\n","label_dict_train = split_and_shuffle_labels(y_data=y_train, seed=seed, amount=train_amount)\n","node_label_info_train, total_label_occurences_train, amount_info_table_train = get_info_for_distribute_non_iid_with_different_n_and_amount(\n","    number_of_samples=number_of_samples, n=n, amount=train_amount, seed=use_seed, min_n_each_node=min_n_each_node)\n","\n","x_train_dict, y_train_dict = distribute_cifar_data_to_participants(label_dict=label_dict_train,\n","                                                                      amount=train_amount,\n","                                                                      number_of_samples=number_of_samples,\n","                                                                      n=n, x_data=x_train,\n","                                                                      y_data=y_train,\n","                                                                      node_label_info=node_label_info_train,\n","                                                                      amount_info_table=amount_info_table_train,\n","                                                                      x_name=\"x_train\",\n","                                                                      y_name=\"y_train\")\n","\n","nodes_list = choose_nodes_randomly_to_convert_hostile(hostile_node_percentage, number_of_samples, hostility_seed)\n","print(\"hostile_nodes:\", nodes_list)\n","\n","if is_organized:\n","    y_train_dict = convert_nodes_to_hostile(y_train_dict, nodes_list,\n","                                               converter_dict={0: 2,\n","                                                               1: 9,\n","                                                               2: 0,\n","                                                               3: 5,\n","                                                               4: 7,\n","                                                               5: 3,\n","                                                               6: 8,\n","                                                               7: 4,\n","                                                               8: 6,\n","                                                               9: 1})\n","else:\n","    y_train_dict = convert_nodes_to_hostile_with_different_converters(y_train_dict, nodes_list,\n","                                                                         converters_seed=converters_seed)\n","\n","## test\n","label_dict_test = split_and_shuffle_labels(y_data=y_test, seed=seed, amount=test_amount)\n","node_label_info_test, total_label_occurences_test, amount_info_table_test = get_info_for_distribute_non_iid_with_different_n_and_amount(\n","    number_of_samples=number_of_samples,\n","    n=n, amount=test_amount, seed=use_seed, min_n_each_node=min_n_each_node)\n","x_test_dict, y_test_dict = distribute_cifar_data_to_participants(label_dict=label_dict_test,\n","                                                                    amount=test_amount,\n","                                                                    number_of_samples=number_of_samples,\n","                                                                    n=n, x_data=x_test,\n","                                                                    y_data=y_test,\n","                                                                    node_label_info=node_label_info_test,\n","                                                                    amount_info_table=amount_info_table_test,\n","                                                                    x_name=\"x_test\",\n","                                                                    y_name=\"y_test\")\n","\n","train_ds = TensorDataset(x_train, y_train)\n","train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n","\n","test_ds = TensorDataset(x_test, y_test)\n","test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n","\n","main_model = Cifar10CNN()\n","weights_init(main_model)\n","main_model = main_model.to(device)\n","\n","main_optimizer = torch.optim.SGD(main_model.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n","main_criterion = nn.CrossEntropyLoss()\n","\n","#changed this one to remove verbose=true error\n","scheduler = lr_scheduler.ReduceLROnPlateau(main_optimizer, mode=\"max\", factor=lr_scheduler_factor,\n","                                           patience=10, threshold=best_threshold, min_lr=min_lr)\n","\n","#scheduler = lr_scheduler.ReduceLROnPlateau(main_optimizer, mode=\"max\", factor=lr_scheduler_factor,\n","                                           #patience=10, threshold=best_threshold, verbose=True, min_lr=min_lr)\n","\n","model_dict, optimizer_dict, criterion_dict = create_model_optimizer_criterion_dict_for_cifar_cnn(number_of_samples, learning_rate,\n","                                                                                                        momentum, device, weight_decay)\n","\n","\n","test_accuracies_of_each_iteration = np.array([], dtype=float)\n","\n","# Create a list to store the iteration numbers\n","iteration_numbers = []  # Added for plotting and CSV file\n","\n","for iteration in range(iteration_num):\n","    iteration_numbers.append(iteration + 1)  # Added for plotting and CSV file\n","    model_dict = send_main_model_to_nodes_and_update_model_dict(main_model, model_dict,\n","                                                                   number_of_samples)\n","\n","    start_train_end_node_process_cifar(number_of_samples, x_train_dict, y_train_dict, x_test_dict,\n","                                          y_test_dict, batch_size, model_dict, criterion_dict,\n","                                          optimizer_dict, numEpoch, device, clipping, clipping_threshold)\n","\n","\n","\n","    main_model = set_averaged_weights_as_main_model_weights_and_update_main_model(main_model, model_dict, device)\n","    test_loss, test_accuracy = validation(main_model, test_dl, main_criterion, device)\n","    scheduler.step(test_accuracy)\n","    new_lr = main_optimizer.param_groups[0][\"lr\"]\n","    optimizer_dict = update_learning_rate_decay(optimizer_dict, new_lr)\n","\n","    test_accuracies_of_each_iteration = np.append(test_accuracies_of_each_iteration, test_accuracy)\n","    print(\"Iteration\", str(iteration + 1), \": main_model accuracy on all test data: {:7.4f}\".format(test_accuracy))\n","\n","# Save the results to a CSV file\n","results_df = pd.DataFrame({'Iteration': iteration_numbers, 'Test Accuracy': test_accuracies_of_each_iteration})  # Added for CSV file\n","results_df.to_csv('results.csv', index=False)  # Added for CSV file\n","\n","    # Plot the graph\n","plt.figure(figsize=(10, 6))  # Added for plotting\n","plt.plot(iteration_numbers, test_accuracies_of_each_iteration)  # Added for plotting\n","plt.title('Accuracy Summary')\n","plt.xlabel('Iteration Number')\n","plt.ylabel('Test Accuracy')\n","plt"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNnCFdW/TNfLlErLL7KD0R5","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}